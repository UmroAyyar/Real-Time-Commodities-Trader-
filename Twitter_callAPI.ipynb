{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f5b193c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in c:\\users\\hasan\\anaconda3\\lib\\site-packages (4.14.0)\n",
      "Requirement already satisfied: oauthlib<4,>=3.2.0 in c:\\users\\hasan\\anaconda3\\lib\\site-packages (from tweepy) (3.2.1)\n",
      "Requirement already satisfied: requests<3,>=2.27.0 in c:\\users\\hasan\\anaconda3\\lib\\site-packages (from tweepy) (2.31.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.2.0 in c:\\users\\hasan\\anaconda3\\lib\\site-packages (from tweepy) (1.3.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hasan\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hasan\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hasan\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hasan\\anaconda3\\lib\\site-packages (from requests<3,>=2.27.0->tweepy) (2023.7.22)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d53df38d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ad61f5ed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Set the path to your credentials JSON file:\n",
    "credentials = \"\\\\Users\\\\hasan\\\\Downloads\\\\credentials1_yt.json\"\n",
    "with open(credentials, \"r\") as keys:\n",
    "    api_tokens = json.load(keys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ef71222",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grab the API keys:\n",
    "API_KEY = api_tokens[\"api_key\"]\n",
    "API_SECRET = api_tokens[\"api_secret\"]\n",
    "BEARER_TOKEN = api_tokens[\"bearer_token\"]\n",
    "ACCESS_TOKEN = api_tokens[\"access_token\"]\n",
    "ACCESS_SECRET = api_tokens[\"access_secret\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75a97e8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We use Tweepy's OAuthHandler method to authenticate our credentials:\n",
    "auth = tweepy.OAuthHandler(API_KEY, API_SECRET)\n",
    "\n",
    "# Then, we set our access tokens by calling the auth object directly:\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_SECRET)\n",
    "\n",
    "# Finally, we can initialize the Twitter API. \n",
    "# NOTE: we will be using this `api` object to interact\n",
    "# with Twitter from here on out:\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "39ec56be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tweets = tweepy.Cursor(api.search_tweets,\n",
    "                       q=\"#covid19\",\n",
    "                       count=100).items(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ed2b0ac",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We can use logical search operators in our query text.\n",
    "# Let's add a series of hashtags with OR, meaning a tweet can\n",
    "# contain any of the search terms:\n",
    "query = \"#cobalt\"\n",
    "\n",
    "# We will also add a new parameter that limits us to English\n",
    "# results only:\n",
    "lang = \"en\"\n",
    "\n",
    "# Ensure extended is set to true:\n",
    "tweet_mode = \"extended\"\n",
    "\n",
    "# Let's limit ourselves to 100 tweets per page:\n",
    "count = 100 \n",
    "\n",
    "# Let's grab only 1000 tweets:\n",
    "tweet_limit = 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "85d9684b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tweet_scraper(query='#cobalt', lang=\"en\", tweet_mode=\"extended\", count=100, tweet_limit=10):\n",
    "    \"\"\"\n",
    "    This function takes Tweepy search_tweets parameters as arguments and returns a Pandas\n",
    "    dataframe containing tweet data.\n",
    "\n",
    "    :param query: a keyword search phrase (string)\n",
    "    :param lang: limit results by language (default: English)\n",
    "    :param tweet_mode: choose whether to extend tweets to full 280 characters.\n",
    "    :param count: the number of tweets to return per page (default: 100; max: 100)\n",
    "    :param tweet_limit: the maximum number of tweets to return (default: 1000).\n",
    "    \"\"\"\n",
    "\n",
    "    # First, let's create a dictionary that will store our tweet data. We\n",
    "    # are using a dictionary because we can easily generate a Pandas dataframe\n",
    "    # from the dictionary keys.\n",
    "    #\n",
    "    # The dictionary will be formatted so that its keys are parameters associated with\n",
    "    # each tweet and its values are lists to which we will append results for each tweet:\n",
    "\n",
    "    data = {\n",
    "        \"user_id\": [], \n",
    "        \"screen_name\": [],\n",
    "        \"name\": [],\n",
    "        \"verified\": [],\n",
    "        \"id\": [],\n",
    "        \"created_at\": [],\n",
    "        \"full_text\": []\n",
    "\n",
    "    }\n",
    "\n",
    "    # Search the tweets as we've already done, but this time, plug in the paremeter values\n",
    "    # from the function arguments:\n",
    "\n",
    "    for tweet in tweepy.Cursor(api.search_tweets, q=query, tweet_mode=tweet_mode, count=count).items(tweet_limit):\n",
    "        \"\"\"\n",
    "        We need to start with user level variables, meaning we are going to iterate\n",
    "        through the user dictionary. We can do this easily! Then, we are going to\n",
    "        append the data to the list in our data dictionary. Let's see how it's\n",
    "        done:\n",
    "        \"\"\"\n",
    "\n",
    "        # User ID:\n",
    "        data[\"user_id\"].append(tweet.user.id)\n",
    "        # Screen name:\n",
    "        data[\"screen_name\"].append(tweet.user.screen_name)\n",
    "        # Name:\n",
    "        data[\"name\"].append(tweet.user.name)\n",
    "        # verified status:\n",
    "        data[\"verified\"].append(tweet.user.verified)\n",
    "\n",
    "#         \"\"\"\n",
    "#         Great! Now let's grab the tweet level data:\n",
    "#         \"\"\"\n",
    "\n",
    "#         # Tweet ID:\n",
    "#         data[\"id\"].append(tweet.id)\n",
    "#         # Date:\n",
    "#         data[\"created_at\"].append(tweet.created_at)\n",
    "#         # Full text of tweet:\n",
    "#         data[\"full_text\"].append(tweet.full_text)\n",
    "#         # Get retweet count:\n",
    "#         data[\"retweet_count\"].append(tweet.retweet_count)\n",
    "#         # Get favorite count:\n",
    "#         data[\"favorite_count\"].append(tweet.favorite_count)\n",
    "        \n",
    "#         # NOTE: to get hashtags & user mentions, we need to iterate through\n",
    "#         # the entities sub dictionary. Then, we need to iterate through\n",
    "#         # the hashtag sub dictionary. It sounds bad, but it's not! \n",
    "#         # We will save the hashtags to a list and append the list\n",
    "#         # to our data dictionary:\n",
    "\n",
    "#         hashtags = []\n",
    "#         # Try to get hashtags; if there is an error, then there are no hashtags\n",
    "#         # and we can pass:\n",
    "#         try:\n",
    "#             for hashtag in tweet.entities[\"hashtags\"]:\n",
    "#                 hashtags.append(hashtag[\"text\"])\n",
    "#         except Exception:\n",
    "#             pass\n",
    "        \n",
    "#         # Now append the hashtag list to our dataset! If there are no\n",
    "#         # hashtags, just set it equal to NaN:\n",
    "#         if len(hashtags) == 0:\n",
    "#             data[\"hashtags\"].append(np.nan)\n",
    "#         else:\n",
    "#             data[\"hashtags\"].append(hashtags)\n",
    "\n",
    "#         # We do the same thing for user mentions:\n",
    "#         mentions = []\n",
    "#         try:\n",
    "#             for mention in tweet.entities[\"user_mentions\"]:\n",
    "#                 mentions.append(mention[\"screen_name\"])\n",
    "#         except Exception:\n",
    "#             pass\n",
    "        \n",
    "\n",
    "#         if len(mentions) == 0:\n",
    "#             data[\"user_mentions\"].append(np.nan)\n",
    "#         else:\n",
    "#             data[\"user_mentions\"].append(mentions)\n",
    "\n",
    "#         # In reply to user id:\n",
    "#         data[\"in_reply_to_user_id\"].append(tweet.in_reply_to_user_id)\n",
    "#         # In reply to user screen name:\n",
    "#         data[\"in_reply_to_screen_name\"].append(tweet.in_reply_to_screen_name)\n",
    "#         # Check if quote status:\n",
    "#         data[\"is_quote_status\"].append(tweet.is_quote_status)\n",
    "\n",
    "#         # We need to check if a tweet is a retweet ourselves. We can do this by checking\n",
    "#         # if the retweeted_status key is present in the JSON:\n",
    "#         if \"retweeted_status\" in tweet._json.keys():\n",
    "#             # Then it is a retweet:\n",
    "#             data[\"is_retweet\"].append(True)\n",
    "#             # Get OG tweet id:\n",
    "#             data[\"retweet_og_id\"].append(tweet.retweeted_status.id)\n",
    "#             # Get OG author ID:\n",
    "#             data[\"retweet_og_author_id\"].append(tweet.retweeted_status.user.id)\n",
    "#             # Get OG author screen name:\n",
    "#             data[\"retweet_og_author_screen_name\"].append(tweet.retweeted_status.user.screen_name)\n",
    "#             # Get OG author name:\n",
    "#             data[\"retweet_og_author_name\"].append(tweet.retweeted_status.user.name)\n",
    "#             # Get date of OG tweet:\n",
    "#             data[\"retweet_og_date\"].append(tweet.retweeted_status.created_at)\n",
    "#             # Get OG full text:\n",
    "#             data[\"retweet_og_full_text\"].append(tweet.retweeted_status.full_text)\n",
    "#             # Get OG retweet count:\n",
    "#             data[\"retweet_og_retweet_count\"].append(tweet.retweeted_status.retweet_count)\n",
    "#             # Get OG favorite count:\n",
    "#             data[\"retweet_og_favorite_count\"].append(tweet.retweeted_status.favorite_count)\n",
    "#         else:\n",
    "#             # Set is_retweet to false and all other values to np.nan:\n",
    "#             data[\"is_retweet\"].append(False)\n",
    "#             data[\"retweet_og_id\"].append(np.nan)\n",
    "#             data[\"retweet_og_author_id\"].append(np.nan)\n",
    "#             data[\"retweet_og_author_screen_name\"].append(np.nan)\n",
    "#             data[\"retweet_og_author_name\"].append(np.nan)\n",
    "#             data[\"retweet_og_date\"].append(np.nan)\n",
    "#             data[\"retweet_og_full_text\"].append(np.nan)\n",
    "#             data[\"retweet_og_retweet_count\"].append(np.nan)\n",
    "#             data[\"retweet_og_favorite_count\"].append(np.nan)\n",
    "    \n",
    "    # Whoo! That's a lot of code. Now, let's turn our data dictionary into a Pandas dataframe\n",
    "    # and then return it:\n",
    "\n",
    "    df = pd.DataFrame(data)\n",
    "\n",
    "    # Now send it out:\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b1cbf3df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "Forbidden",
     "evalue": "403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mForbidden\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m tweet_limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m10\u001b[39m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Call the function using our parameters:\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mtweet_scraper\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtweet_mode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcount\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcount\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtweet_limit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtweet_limit\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[20], line 34\u001b[0m, in \u001b[0;36mtweet_scraper\u001b[1;34m(query, lang, tweet_mode, count, tweet_limit)\u001b[0m\n\u001b[0;32m     20\u001b[0m data \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muser_id\u001b[39m\u001b[38;5;124m\"\u001b[39m: [], \n\u001b[0;32m     22\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mscreen_name\u001b[39m\u001b[38;5;124m\"\u001b[39m: [],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     28\u001b[0m \n\u001b[0;32m     29\u001b[0m }\n\u001b[0;32m     31\u001b[0m \u001b[38;5;66;03m# Search the tweets as we've already done, but this time, plug in the paremeter values\u001b[39;00m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# from the function arguments:\u001b[39;00m\n\u001b[1;32m---> 34\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tweet \u001b[38;5;129;01min\u001b[39;00m tweepy\u001b[38;5;241m.\u001b[39mCursor(api\u001b[38;5;241m.\u001b[39msearch_tweets, q\u001b[38;5;241m=\u001b[39mquery, tweet_mode\u001b[38;5;241m=\u001b[39mtweet_mode, count\u001b[38;5;241m=\u001b[39mcount)\u001b[38;5;241m.\u001b[39mitems(tweet_limit):\n\u001b[0;32m     35\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     36\u001b[0m \u001b[38;5;124;03m    We need to start with user level variables, meaning we are going to iterate\u001b[39;00m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;124;03m    through the user dictionary. We can do this easily! Then, we are going to\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;124;03m    append the data to the list in our data dictionary. Let's see how it's\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;124;03m    done:\u001b[39;00m\n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m     42\u001b[0m     \u001b[38;5;66;03m# User ID:\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:286\u001b[0m, in \u001b[0;36mItemIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    283\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    284\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_index \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    285\u001b[0m     \u001b[38;5;66;03m# Reached end of current page, get the next page...\u001b[39;00m\n\u001b[1;32m--> 286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpage_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    287\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    288\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_page \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpage_iterator)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:86\u001b[0m, in \u001b[0;36mBaseIterator.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m---> 86\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnext\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\cursor.py:167\u001b[0m, in \u001b[0;36mIdIterator.next\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    164\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[0;32m    166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mresults) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m--> 167\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod(max_id\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_id, parser\u001b[38;5;241m=\u001b[39mRawParser(), \u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwargs)\n\u001b[0;32m    169\u001b[0m     model \u001b[38;5;241m=\u001b[39m ModelParser()\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    170\u001b[0m         data, api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[0;32m    171\u001b[0m         payload_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_list,\n\u001b[0;32m    172\u001b[0m         payload_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_type\n\u001b[0;32m    173\u001b[0m     )\n\u001b[0;32m    174\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m\u001b[38;5;241m.\u001b[39mparser\u001b[38;5;241m.\u001b[39mparse(\n\u001b[0;32m    175\u001b[0m         data, api \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__self__\u001b[39m,\n\u001b[0;32m    176\u001b[0m         payload_list\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_list,\n\u001b[0;32m    177\u001b[0m         payload_type\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39mpayload_type\n\u001b[0;32m    178\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py:33\u001b[0m, in \u001b[0;36mpagination.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(method)\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m---> 33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py:46\u001b[0m, in \u001b[0;36mpayload.<locals>.decorator.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     44\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_list\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_list\n\u001b[0;32m     45\u001b[0m kwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpayload_type\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m payload_type\n\u001b[1;32m---> 46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m method(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py:1146\u001b[0m, in \u001b[0;36mAPI.search_tweets\u001b[1;34m(self, q, **kwargs)\u001b[0m\n\u001b[0;32m   1052\u001b[0m \u001b[38;5;129m@pagination\u001b[39m(mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1053\u001b[0m \u001b[38;5;129m@payload\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch_results\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m   1054\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_tweets\u001b[39m(\u001b[38;5;28mself\u001b[39m, q, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m   1055\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"search_tweets(q, *, geocode, lang, locale, result_type, count, \\\u001b[39;00m\n\u001b[0;32m   1056\u001b[0m \u001b[38;5;124;03m                     until, since_id, max_id, include_entities)\u001b[39;00m\n\u001b[0;32m   1057\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[38;5;124;03m    .. _Twitter's documentation on the standard search API: https://developer.twitter.com/en/docs/twitter-api/v1/tweets/search/overview\u001b[39;00m\n\u001b[0;32m   1145\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1146\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrequest(\n\u001b[0;32m   1147\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mGET\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msearch/tweets\u001b[39m\u001b[38;5;124m'\u001b[39m, endpoint_parameters\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1148\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mq\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgeocode\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlang\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlocale\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mresult_type\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcount\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   1149\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muntil\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msince_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_id\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minclude_entities\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m   1150\u001b[0m         ), q\u001b[38;5;241m=\u001b[39mq, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[0;32m   1151\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\tweepy\\api.py:271\u001b[0m, in \u001b[0;36mAPI.request\u001b[1;34m(self, method, endpoint, endpoint_parameters, params, headers, json_payload, parser, payload_list, payload_type, post_data, files, require_auth, return_cursors, upload_api, use_cache, **kwargs)\u001b[0m\n\u001b[0;32m    269\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Unauthorized(resp)\n\u001b[0;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m--> 271\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m Forbidden(resp)\n\u001b[0;32m    272\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m resp\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m404\u001b[39m:\n\u001b[0;32m    273\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NotFound(resp)\n",
      "\u001b[1;31mForbidden\u001b[0m: 403 Forbidden\n453 - You currently have access to a subset of Twitter API v2 endpoints and limited v1.1 endpoints (e.g. media post, oauth) only. If you need access to this endpoint, you may need a different access level. You can learn more here: https://developer.twitter.com/en/portal/product"
     ]
    }
   ],
   "source": [
    "\n",
    "# Set the function parameters:\n",
    "query = \"#cobalt\"\n",
    "lang = \"en\"\n",
    "tweet_mode = \"extended\"\n",
    "count = 100 \n",
    "tweet_limit = 10\n",
    "\n",
    "# Call the function using our parameters:\n",
    "df = tweet_scraper(query=query, lang=lang, tweet_mode=tweet_mode, count=count, tweet_limit=tweet_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "460826df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b03d37b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758591ce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
